{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Notebook for the Duffing Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "from scipy.integrate import solve_ivp\n",
    "from tqdm.auto import trange\n",
    "\n",
    "# Add parent directory to sys.path\n",
    "from pathlib import Path\n",
    "current_path = Path.cwd()\n",
    "parent_dir = current_path.parent.parent\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "# Import necessary modules\n",
    "from src.train import run_model, run_model_non_linear\n",
    "from src.utils_plot import plot_loss_and_all_solution, plot_head_loss, plot_loss_and_single_solution\n",
    "from src.load_save import save_model\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "torch.autograd.profiler.profile(False)\n",
    "torch.autograd.profiler.emit_nvtx(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_versions_and_device():\n",
    "  # set the device to the GPU if it is available, otherwise use the CPU\n",
    "  current_dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  !nvidia-smi\n",
    "  return current_dev\n",
    "\n",
    "# set a global device variable to use in code\n",
    "dev = check_versions_and_device()\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1) Multi Head Training (linear form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select equation parameter\n",
    "\n",
    "-   number of head\n",
    "-   stiffness parameter $\\alpha$\n",
    "-   force function $f$\n",
    "-   initiales condition $IC$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 12\n",
    "equation_name = \"Duffing\"\n",
    "\n",
    "np.random.seed(42)\n",
    "# generate the training stiffness parameter alpha\n",
    "alpha_bounds = (5, 20)\n",
    "def generate_alpha(k, alpha_bounds = alpha_bounds):\n",
    "  alpha_list = np.zeros(k)\n",
    "  for i in range(k):\n",
    "    alpha_list[i] = np.random.uniform(alpha_bounds[0], alpha_bounds[1])\n",
    "  return alpha_list\n",
    "alpha_list = generate_alpha(num_heads)\n",
    "def get_A(alpha):\n",
    "    return torch.tensor([[0., -1.], [0.1, alpha]], device=dev).double() \n",
    "A_list = [get_A(i)for i in alpha_list]\n",
    "\n",
    "IC_list = [torch.tensor([[1.], [0.5]], device=dev).double() for _ in range(num_heads)]\n",
    "# uncomment the above line to use random IC on all head\n",
    "def random_IC(x_bound=[1, 3], y_bound=[0, 2]):\n",
    "    ICx = np.random.uniform(x_bound[0], x_bound[1], 1)\n",
    "    ICy = np.random.uniform(y_bound[0], y_bound[1], 1)\n",
    "    return torch.tensor([ICx, ICy], device=dev)\n",
    "#IC_list = [random_IC() for i in range(num_heads)]\n",
    "\n",
    "force_list = [\n",
    "    lambda t: torch.cat([torch.zeros(len(t), device=dev).unsqueeze(1), torch.cos(t).unsqueeze(1)], dim=1).double()\n",
    "    if not isinstance(t, (float, int))\n",
    "    else np.array([0, np.cos(t)]).T\n",
    "    for _ in range(num_heads)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select training parameter\n",
    "\n",
    "-   range of training $x_{range}$\n",
    "-   activation function\n",
    "-   number of hidden layer\n",
    "-   number of equation\n",
    "-   number of iterations\n",
    "-   learning rate $lr$\n",
    "-   sample size during epoch\n",
    "-   gradient decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = [0, 10]\n",
    "activation = \"silu\"\n",
    "hid_lay = list(np.array([128, 128, 256, 512]))\n",
    "hid_lay = list(np.array([128, 128, 132]))\n",
    "num_equations = 2\n",
    "iterations = 100\n",
    "sample_size = 200\n",
    "lr = 1e-4\n",
    "decay = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the multi head model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "# run model which has two non-coupled equations\n",
    "loss_hist, trained_model, model_time = run_model(iterations=iterations, x_range=x_range, lr=lr,\n",
    "                                                     A_list=A_list, IC_list=IC_list, force=force_list,\n",
    "                                                     hid_lay=hid_lay, activation=activation,\n",
    "                                                     num_equations=num_equations, num_heads=num_heads,\n",
    "                                                     sample_size = sample_size, decay=decay, dev=dev,\n",
    "                                                     verbose=verbose, true_functs=None, save=False)\n",
    "\n",
    "# date tag to save\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "# Format the date and time as a string in the format 'mmddhhmm'\n",
    "formatted_datetime = now.strftime('%m%d%H%M')\n",
    "# Convert the formatted string to an integer\n",
    "formatted_datetime_int = int(formatted_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to numerically compute the solution to any set of two coupled, linear first-order ODES\n",
    "def double_coupled_equation(t, y, A, force):\n",
    "    return np.array([force(t)[0] - A[0][1] * y[1] - A[0][0] * y[0],\n",
    "                     force(t)[1] - A[1][0] * y[0] - A[1][1] * y[1]])\n",
    "\n",
    "numerical_sol_fct = lambda x, v, A, force: (solve_ivp(double_coupled_equation, [x_range[0], x_range[1]],\n",
    "                                                    v.squeeze(), args=(A, force), t_eval=x.squeeze(), method=\"Radau\").y)\n",
    "\n",
    "plot_loss_and_all_solution(x_range=x_range, true_functs=numerical_sol_fct,\n",
    "                           trained_model=trained_model, IC_list=IC_list, A_list=A_list,\n",
    "                           force=force_list, train_losses=loss_hist, device=dev)\n",
    "plot_head_loss(loss_hist[\"head\"], alpha_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model and training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"base_model_2\"\n",
    "save_model(trained_model, formatted_datetime_int, equation_name, model_name,\n",
    "           x_range, iterations, hid_lay, num_equations, num_heads, A_list,\n",
    "           IC_list, force_list, alpha_list, loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Multi Head Training (nonlinear form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select equation parameter\n",
    "\n",
    "-   number of head\n",
    "-   stiffness parameter $\\alpha$\n",
    "-   initiales condition $IC$\n",
    "-   $\\beta$ non linear parameter\n",
    "-   nonlinear equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 4\n",
    "equation_name = \"Duffing\"\n",
    "\n",
    "np.random.seed(42)\n",
    "# generate the training stiffness parameter alpha\n",
    "alpha_bounds = (1, 10)\n",
    "def generate_alpha(k, alpha_bounds = alpha_bounds):\n",
    "  alpha_list = np.zeros(k)\n",
    "  for i in range(k):\n",
    "    alpha_list[i] = np.random.uniform(alpha_bounds[0], alpha_bounds[1])\n",
    "  return alpha_list\n",
    "alpha_list = generate_alpha(num_heads)\n",
    "\n",
    "beta = 0.5\n",
    "\n",
    "def equation(t, y, alpha, beta=beta):\n",
    "    if isinstance(y, torch.Tensor):\n",
    "      yp = torch.zeros_like(y)\n",
    "      force = torch.cos(t)\n",
    "    elif isinstance(y, np.ndarray):\n",
    "      yp = np.zeros_like(y)\n",
    "      force = np.cos(t)\n",
    "    yp[..., 0] = y[..., 1]\n",
    "    yp[..., 1] = -0.1*y[..., 0] - alpha*y[..., 1] - beta*y[..., 0]**3 + force\n",
    "    return yp\n",
    "equation_list = [lambda t, y, Alpha=alpha: equation(t, y, Alpha) for alpha in alpha_list]\n",
    "\n",
    "\n",
    "IC_list = [torch.tensor([[1.], [0.5]], device=dev).double() for _ in range(num_heads)]\n",
    "# uncomment the above line to use random IC on all head\n",
    "def random_IC(x_bound=[1.5, 2.5], y_bound=[0, 0]):\n",
    "    ICx = np.random.uniform(x_bound[0], x_bound[1], 1)\n",
    "    ICy = np.random.uniform(y_bound[0], y_bound[1], 1)\n",
    "    return torch.tensor([ICx, ICy], device=dev)\n",
    "#IC_list = [random_IC() for i in range(num_heads)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select training parameter\n",
    "\n",
    "-   range of training $x_{range}$\n",
    "-   activation function\n",
    "-   number of hidden layer\n",
    "-   number of equation\n",
    "-   number of iterations\n",
    "-   learning rate $lr$\n",
    "-   sample size during epoch\n",
    "-   gradient decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = [0, 10]\n",
    "activation = \"silu\"\n",
    "hid_lay = list(np.array([128, 128, 256, 512]))\n",
    "reparametrization = True\n",
    "num_equations = 2\n",
    "iterations = 100\n",
    "sample_size = 200\n",
    "lr = 1e-4\n",
    "decay = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the multi head model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "# run model which has two non-coupled equations\n",
    "loss_hist, trained_model, model_time = run_model_non_linear(iterations=iterations, x_range=x_range, lr=lr,\n",
    "                                                            equation_list=equation_list, IC_list=IC_list,\n",
    "                                                            hid_lay=hid_lay, activation=activation,\n",
    "                                                            num_equations=num_equations, num_heads=num_heads,\n",
    "                                                            sample_size = sample_size, decay=decay, dev=dev, verbose=verbose,\n",
    "                                                            true_functs=None, reparametrization=reparametrization)\n",
    "\n",
    "# date tag to save\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "# Format the date and time as a string in the format 'mmddhhmm'\n",
    "formatted_datetime = now.strftime('%m%d%H%M')\n",
    "# Convert the formatted string to an integer\n",
    "formatted_datetime_int = int(formatted_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_sol_fct = lambda x, v, alpha, beta: (solve_ivp(equation, [x_range[0], x_range[1]],\n",
    "                                                    v.squeeze(), args=(alpha, beta), t_eval=x.squeeze(), method=\"Radau\").y.T)\n",
    "numerical_sol_list = [lambda x, IC=ic.detach().cpu().numpy(), Alpha=alpha, beta=beta: numerical_sol_fct(x, IC, Alpha, beta) for ic, alpha in zip(IC_list, alpha_list)]\n",
    "\n",
    "plot_loss_and_all_solution(x_range=x_range, true_functs=numerical_sol_list,\n",
    "                           trained_model=trained_model, IC_list=IC_list,\n",
    "                           A_list=None, force=None, train_losses=loss_hist,\n",
    "                           device=dev, equation_list=equation_list, reparametrization=reparametrization)\n",
    "plot_head_loss(loss_hist[\"head\"], alpha_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model and training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nonlinear_repara\"\n",
    "A_list=[torch.tensor([np.nan])]\n",
    "force_list = [torch.tensor([np.nan])]\n",
    "save_model(trained_model, formatted_datetime_int, equation_name, model_name,\n",
    "           x_range, iterations, hid_lay, num_equations, num_heads, A_list,\n",
    "           IC_list, force_list, alpha_list, loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Single Head Training (nonlinear form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select equation parameter\n",
    "\n",
    "-   stiffness parameter $\\alpha$\n",
    "-   initiales condition $IC$\n",
    "-   $\\beta$ non linear parameter\n",
    "-   nonlinear equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 1\n",
    "alpha_list = [2, 20, 30, 40]\n",
    "beta = 0.5\n",
    "equation_list = [lambda t, y, Alpha=alpha: equation(t, y, Alpha) for alpha in alpha_list]\n",
    "IC_list = [torch.tensor([[1.], [0.5]], device=dev).double() for _ in alpha_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select training parameter\n",
    "\n",
    "-   number of iterations\n",
    "-   learning rate $lr$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [0.0001, 0.00008, 0.00004, 0.00001]\n",
    "iterations_list = [20000, 30000, 40000, 50000]\n",
    "iterations_list = [5000, 20, 30, 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train single head model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_PINNS = []\n",
    "rng = np.random.default_rng()\n",
    "t_eval = torch.arange(x_range[0], x_range[1], 0.001, requires_grad=True, device=dev).double()\n",
    "t_eval = t_eval[np.concatenate(([0], rng.choice(range(1, len(t_eval)), size=512 - 1, replace=False)))]\n",
    "t_eval = t_eval.reshape(-1, 1)\n",
    "t_eval, _ = t_eval.sort(dim=0)\n",
    "\n",
    "for i in trange(len(alpha_list)):\n",
    "    if i==0:\n",
    "        loss_history, trained_model, _ = run_model_non_linear(iterations=iterations_list[i], x_range=x_range, lr=lr_list[i],\n",
    "                                                               equation_list=[equation_list[i]], IC_list=[IC_list[i]],\n",
    "                                                               hid_lay=hid_lay, activation=activation,\n",
    "                                                               num_equations=num_equations, num_heads=num_heads,\n",
    "                                                               sample_size = sample_size, decay=decay, dev=dev, verbose=True,\n",
    "                                                               true_functs=None, reparametrization=reparametrization)\n",
    "    else:\n",
    "        _, _, _ = run_model_non_linear(iterations=iterations_list[i], x_range=x_range, lr=lr_list[i],\n",
    "                                                               equation_list=[equation_list[i]], IC_list=[IC_list[i]],\n",
    "                                                               hid_lay=hid_lay, activation=activation,\n",
    "                                                               num_equations=num_equations, num_heads=num_heads,\n",
    "                                                               sample_size = sample_size, decay=decay, dev=dev, verbose=False,\n",
    "                                                               true_functs=None, reparametrization=reparametrization)\n",
    "    solution_PINNS.append(trained_model(t_eval, reparametrization=reparametrization)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training of the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_sol_list = [lambda x, IC=ic.detach().cpu().numpy(), Alpha=alpha, beta=beta: numerical_sol_fct(x, IC, Alpha, beta) for ic, alpha in zip(IC_list, alpha_list)]\n",
    "\n",
    "plot_loss_and_single_solution(x_range=x_range, true_functs=numerical_sol_list,\n",
    "                              trained_model=trained_model, IC_list=IC_list, A_list=None,\n",
    "                              force=None, train_losses=loss_history, equation_list=equation_list, \n",
    "                              reparametrization=reparametrization, device=dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MAE and MaxAE results over several alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_y1 = []\n",
    "mae_y2 = []\n",
    "maxae_y1 = []\n",
    "maxae_y2 = []\n",
    "\n",
    "for i in range(len(alpha_list)):\n",
    "    true_funct = lambda x: numerical_sol_fct(x, v=IC_list[0].detach().cpu().numpy(), alpha=alpha_list[i], beta=beta)\n",
    "    pinns = solution_PINNS[i].detach().cpu().numpy()\n",
    "    numerical = true_funct(t_eval.detach().cpu().numpy())\n",
    "    absolute_error = np.abs(pinns[:, 0, :] - numerical)\n",
    "    mae_y1.append(absolute_error.mean(0)[0])\n",
    "    mae_y2.append(absolute_error.mean(0)[1])\n",
    "    maxae_y1.append(absolute_error.max(0)[0])\n",
    "    maxae_y2.append(absolute_error.max(0)[1])\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(13, 4))\n",
    "\n",
    "ax.plot(alpha_list, mae_y1, \"-o\", label=\"$MAE$ ${y_1}$\", linewidth=2, markersize=6)\n",
    "ax.plot(alpha_list, mae_y2,\"-o\", label=\"$MAE$ ${y_2}$\", linewidth=2, markersize=6)\n",
    "ax.plot(alpha_list, maxae_y1, \"-x\", color=\"#1f77b4\", label=\"$MaxAE$  ${y_1}$\", linewidth=2, markersize=8)\n",
    "ax.plot(alpha_list, maxae_y2, \"-x\", color=\"#ff7f0e\", label=\"$MaxAE$ ${y_2}$\", linewidth=2, markersize=8)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_title(r\"Mean and Max Absolute Error with increasing Stiffness\", fontsize=20)\n",
    "ax.set_xlabel(r'Stiffness parameter $\\alpha$', fontsize=16)\n",
    "ax.set_ylabel('Absolute Error', fontsize=16)\n",
    "ax.set_xticks(alpha_list, [rf\"$\\alpha$={i}\" for i in alpha_list])\n",
    "ax.set_yticks([0.1, 0.01, 0.001, 0.0001],\n",
    "              [r\"$10^{-1}$\", r\"$10^{-2}$\", r\"$10^{-3}$\", r\"$10^{-4}$\"])\n",
    "ax.grid()\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "ax.legend(loc='best', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save MAE and MaxAE results over several alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history[\"alpha_list\"] = alpha_list\n",
    "history[\"mae_y1\"] = mae_y1\n",
    "history[\"mae_y2\"] = mae_y2\n",
    "history[\"maxae_y1\"] = maxae_y1\n",
    "history[\"maxae_y2\"] = maxae_y2\n",
    "\n",
    "current_path = Path.cwd().parent.parent\n",
    "path = os.path.join(current_path, \"result_history\")\n",
    "with open(os.path.join(path, \"Duffing_Error_Trained.json\"),  \"w\") as fp:\n",
    "    json.dump(history, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
