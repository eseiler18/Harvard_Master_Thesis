{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for the LBFGS transfer learning on Duffing Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "from scipy.integrate import solve_ivp\n",
    "from tqdm.auto import tqdm, trange\n",
    "import os\n",
    "\n",
    "# Add parent directory to sys.path\n",
    "from pathlib import Path\n",
    "current_path = Path.cwd()\n",
    "parent_dir = current_path.parent.parent\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "# Import necessary modules\n",
    "from src.utils_plot import plot_loss_and_all_solution, plot_transfer_learned_LBFGS\n",
    "\n",
    "from src.load_save import load_run_history\n",
    "from src.nonlinear_transfer_learning import GD_transfer_learning\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "torch.autograd.profiler.profile(False)\n",
    "torch.autograd.profiler.emit_nvtx(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_versions_and_device():\n",
    "  # set the device to the GPU if it is available, otherwise use the CPU\n",
    "  current_dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  !nvidia-smi\n",
    "  return current_dev\n",
    "\n",
    "# set a global device variable to use in code\n",
    "dev = check_versions_and_device()\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pretrain model and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"nonlinear_repara_2141608\"\n",
    "equation_name = \"duffing\"\n",
    "\n",
    "trained_model, \\\n",
    "x_range, \\\n",
    "iterations, \\\n",
    "hid_lay, \\\n",
    "num_equations, \\\n",
    "num_heads, \\\n",
    "loss_hist, \\\n",
    "alpha_list, \\\n",
    "A_list, \\\n",
    "IC_list, \\\n",
    "force_list = load_run_history(equation_name, file_name, dev, prev=False)\n",
    "\n",
    "reparametrization=True\n",
    "beta=0.5\n",
    "def equation(t, y, alpha, beta=beta):\n",
    "    if isinstance(y, torch.Tensor):\n",
    "      yp = torch.zeros_like(y)\n",
    "      force = torch.cos(t)\n",
    "    elif isinstance(y, np.ndarray):\n",
    "      yp = np.zeros_like(y)\n",
    "      force = np.cos(t)\n",
    "    yp[..., 0] = y[..., 1]\n",
    "    yp[..., 1] = -0.1*y[..., 0] - alpha*y[..., 1] - beta*y[..., 0]**3 + force\n",
    "    return yp\n",
    "equation_list = [lambda t, y, Alpha=alpha: equation(t, y, Alpha) for alpha in alpha_list]\n",
    "\n",
    "numerical_sol_fct = lambda x, v, alpha, beta: (solve_ivp(equation, [x_range[0], x_range[1]],\n",
    "                                                    v.squeeze(), args=(alpha, beta), t_eval=x.squeeze(), method=\"Radau\").y.T)\n",
    "numerical_sol_list = [lambda x, IC=ic.detach().cpu().numpy(), Alpha=alpha, beta=beta: numerical_sol_fct(x, IC, Alpha, beta) for ic, alpha in zip(IC_list, alpha_list)]\n",
    "\n",
    "plot_loss_and_all_solution(x_range=x_range, true_functs=numerical_sol_list,\n",
    "                           trained_model=trained_model, IC_list=IC_list,\n",
    "                           A_list=None, force=None, train_losses=loss_hist,\n",
    "                           device=dev, equation_list=equation_list,\n",
    "                           reparametrization=reparametrization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBFGS transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose transfer equation an learning parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_transfer = 10\n",
    "equation_transfer = lambda t, y, Alpha=alpha_transfer: equation(t, y, Alpha)\n",
    "IC = IC_list[0]\n",
    "\n",
    "lr=1\n",
    "iterations=5\n",
    "N=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_transfer, model_transfer, time_transfer = GD_transfer_learning(iterations=iterations, x_range=x_range, N=N,\n",
    "                                                                    equation_transfer=equation_transfer, IC=IC,\n",
    "                                                                    num_equations=num_equations, dev=dev, hid_lay=hid_lay,\n",
    "                                                                    pretrained_model=trained_model, lr=lr, optimizer_name=\"LBFGS\",\n",
    "                                                                    decay=False, gamma=0.1, reparametrization=reparametrization, tqdm_bool=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot learning result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "t_eval = torch.arange(x_range[0], x_range[1], 0.001, requires_grad=True, device=dev).double()\n",
    "t_eval = t_eval[np.concatenate(([0], rng.choice(range(1, len(t_eval)), size=512 - 1, replace=False)))]\n",
    "t_eval = t_eval.reshape(-1, 1)\n",
    "t_eval, _ = t_eval.sort(dim=0)\n",
    "\n",
    "true_funct = lambda x: numerical_sol_fct(x, v=IC.detach().cpu().numpy(), alpha=alpha_transfer, beta=beta)\n",
    "plot_transfer_learned_LBFGS(H=None, W_out=model_transfer, t_eval=t_eval, v=IC, A=None, force=None,\n",
    "                            num_equations=num_equations, true_funct=true_funct,\n",
    "                            transfer_loss=loss_transfer, reparametrization=reparametrization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBFGS transfer leaning in several alpha regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose training and equation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 1\n",
    "alpha_list = [5, 10, 15, 20, 25, 30, 35, 40]\n",
    "\n",
    "lr_list = [1, 1, 1, 0.5, 0.2, 0.1, 0.1, 0.05]\n",
    "iterations_list = [10, 15, 20, 20, 20, 20, 20, 30]\n",
    "iterations_list = [3, 3, 3, 3, 3, 3, 3, 3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_PINNS = []\n",
    "rng = np.random.default_rng()\n",
    "t_eval = torch.arange(x_range[0], x_range[1], 0.001, requires_grad=True, device=dev).double()\n",
    "t_eval = t_eval[np.concatenate(([0], rng.choice(range(1, len(t_eval)), size=512 - 1, replace=False)))]\n",
    "t_eval = t_eval.reshape(-1, 1)\n",
    "t_eval, _ = t_eval.sort(dim=0)\n",
    "\n",
    "for i in trange(len(alpha_list)):\n",
    "    equation_transfer = lambda t, y, Alpha=alpha_list[i]: equation(t, y, Alpha)\n",
    "    _, model_transfer, _ = GD_transfer_learning(iterations=iterations_list[i], x_range=x_range, N=500,\n",
    "                                             equation_transfer=equation_transfer, IC=IC_list[0],\n",
    "                                             num_equations=num_equations, dev=dev, hid_lay=hid_lay,\n",
    "                                             pretrained_model=trained_model, lr=lr_list[i], optimizer_name=\"LBFGS\",\n",
    "                                             decay=False, gamma=0.1, reparametrization=reparametrization, tqdm_bool=True)\n",
    "    solution_PINNS.append(model_transfer(t_eval, reparametrization=reparametrization)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MAE and MaxAE results over several alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_y1 = []\n",
    "mae_y2 = []\n",
    "maxae_y1 = []\n",
    "maxae_y2 = []\n",
    "\n",
    "for i in range(len(alpha_list)):\n",
    "    true_funct = lambda x: numerical_sol_fct(x, v=IC_list[0].detach().cpu().numpy(), alpha=alpha_list[i], beta=beta)\n",
    "    pinns = solution_PINNS[i].detach().cpu().numpy()\n",
    "    numerical = true_funct(t_eval.detach().cpu().numpy())\n",
    "    absolute_error = np.abs(pinns[:, 0, :] - numerical)\n",
    "    mae_y1.append(absolute_error.mean(0)[0])\n",
    "    mae_y2.append(absolute_error.mean(0)[1])\n",
    "    maxae_y1.append(absolute_error.max(0)[0])\n",
    "    maxae_y2.append(absolute_error.max(0)[1])\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(13, 4))\n",
    "\n",
    "ax.plot(alpha_list, mae_y1, \"-o\", label=\"$MAE$ ${y_1}$\", linewidth=2, markersize=6)\n",
    "ax.plot(alpha_list, mae_y2,\"-o\", label=\"$MAE$ ${y_2}$\", linewidth=2, markersize=6)\n",
    "ax.plot(alpha_list, maxae_y1, \"-x\", color=\"#1f77b4\", label=\"$MaxAE$ ${y_1}$\", linewidth=2, markersize=8)\n",
    "ax.plot(alpha_list, maxae_y2, \"-x\", color=\"#ff7f0e\", label=\"$MaxAE$ ${y_2}$\", linewidth=2, markersize=8)\n",
    "\n",
    "#ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_title(r\"Mean and Max Absolute Error with increasing Stiffness\", fontsize=20)\n",
    "ax.set_xlabel(r'Stiffness parameter $\\alpha$', fontsize=16)\n",
    "ax.set_ylabel('Absolute Error', fontsize=16)\n",
    "ax.set_xticks(alpha_list)\n",
    "ax.set_yticks([0.1, 0.01, 0.001, 0.0001],\n",
    "              [r\"$10^{-1}$\", r\"$10^{-2}$\", r\"$10^{-3}$\", r\"$10^{-4}$\"])\n",
    "ax.grid()\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "ax.legend(loc='best', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save MAE and MaxAE results over several alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history[\"alpha_list\"] = alpha_list\n",
    "history[\"mae_y1\"] = mae_y1\n",
    "history[\"mae_y2\"] = mae_y2\n",
    "history[\"maxae_y1\"] = maxae_y1\n",
    "history[\"maxae_y2\"] = maxae_y2\n",
    "\n",
    "current_path = Path.cwd().parent.parent\n",
    "path = os.path.join(current_path, \"result_history\")\n",
    "with open(os.path.join(path, \"Duffing_Error_Trained.json\"),  \"w\") as fp:\n",
    "    json.dump(history, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
