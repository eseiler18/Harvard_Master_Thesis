{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Notebook for the Damped Harmonic Ocsillator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "from scipy.integrate import solve_ivp\n",
    "from tqdm.auto import trange\n",
    "\n",
    "# Add parent directory to sys.path\n",
    "from pathlib import Path\n",
    "current_path = Path.cwd()\n",
    "parent_dir = current_path.parent.parent\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "# Import necessary modules\n",
    "from src.train import run_model\n",
    "from src.utils_plot import plot_loss_and_all_solution, plot_head_loss, plot_loss_and_single_solution\n",
    "from src.load_save import save_model\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "torch.autograd.profiler.profile(False)\n",
    "torch.autograd.profiler.emit_nvtx(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_versions_and_device():\n",
    "  # set the device to the GPU if it is available, otherwise use the CPU\n",
    "  current_dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  !nvidia-smi\n",
    "  return current_dev\n",
    "\n",
    "# set a global device variable to use in code\n",
    "dev = check_versions_and_device()\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1) Multi Head Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select equation parameter\n",
    "\n",
    "-   number of head\n",
    "-   stiffness parameter $\\alpha$\n",
    "-   force function $f$\n",
    "-   initiales condition $IC$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equation_name = \"DHO\"\n",
    "num_heads = 4\n",
    "\n",
    "alpha_list = [1, 2, 3, 4]\n",
    "A_list = [torch.tensor([[0., -1.], [1., 2*i]], device=dev).double() for i in alpha_list]\n",
    "\n",
    "force_list = [torch.tensor([[0.], [0.]], device=dev).double() for _ in range(num_heads)]\n",
    "IC_list = [torch.tensor([[1.], [0.5]], device=dev).double() for _ in range(num_heads)]\n",
    "\n",
    "# uncomment the above line to use random IC on all head\n",
    "def random_IC(x_bound=[0, 5], y_bound=[0, 5]):\n",
    "    ICx = np.random.uniform(x_bound[0], x_bound[1], 1)\n",
    "    ICy = np.random.uniform(y_bound[0], y_bound[1], 1)\n",
    "    return torch.tensor([ICx, ICy], device=dev).double()\n",
    "# IC_list = [random_IC() for i in range(num_heads)]\n",
    "\n",
    "# uncomment the above line to use random force function on all head\n",
    "def random_force(force1_bound=[0, 2], force2_bound=[0, 2]):\n",
    "    force1 = np.random.uniform(force1_bound[0], force1_bound[1], 1)\n",
    "    force2 = np.random.uniform(force2_bound[0], force2_bound[1], 1)\n",
    "    return torch.tensor([force1, force2], device=dev).double()\n",
    "# force_list = [random_force() for i in range(num_heads)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select training parameter\n",
    "\n",
    "-   range of training $x_{range}$\n",
    "-   activation function\n",
    "-   number of hidden layer\n",
    "-   number of equation\n",
    "-   number of iterations\n",
    "-   learning rate $lr$\n",
    "-   sample size during epoch\n",
    "-   gradient decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = [0, 10]\n",
    "activation = \"silu\"\n",
    "hid_lay = list(np.array([124, 124, 132]) * 1)\n",
    "num_equations = 2\n",
    "iterations = 2000\n",
    "lr = 0.001\n",
    "sample_size = 512\n",
    "decay=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the multi head model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "loss_hist, trained_model, model_time = run_model(iterations=iterations, x_range=x_range, lr=lr, A_list=A_list, \n",
    "                                                  IC_list=IC_list, force=force_list, hid_lay=hid_lay, activation=activation,\n",
    "                                                  num_equations=num_equations, num_heads=num_heads, sample_size=sample_size,\n",
    "                                                  decay=decay, dev=dev, verbose=verbose)\n",
    "\n",
    "# date tag to save\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "# Format the date and time as a string in the format 'mmddhhmm'\n",
    "formatted_datetime = now.strftime('%m%d%H%M')\n",
    "# Convert the formatted string to an integer\n",
    "formatted_datetime_int = int(formatted_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to numerically compute the solution use the Radau method\n",
    "def double_coupled_equation(t, y, A, force):\n",
    "    return np.array([force[0].detach().item() - A[0][1] * y[1] - A[0][0] * y[0],\n",
    "                     force[1].detach().item() - A[1][0] * y[0] - A[1][1] * y[1]])\n",
    "\n",
    "numerical_sol_fct = lambda x, v, A, force: (solve_ivp(double_coupled_equation, [x_range[0], x_range[1]],\n",
    "                                                    v.squeeze(), args=(A, force), t_eval=x.squeeze(), method=\"Radau\").y)\n",
    "\n",
    "plot_loss_and_all_solution(x_range=x_range, true_functs=numerical_sol_fct,\n",
    "                           trained_model=trained_model, IC_list=IC_list, A_list=A_list,\n",
    "                           force=force_list, train_losses=loss_hist, device=dev)\n",
    "\n",
    "plot_head_loss(loss_hist[\"head\"], alpha_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model and training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"test\"\n",
    "\n",
    "save_model(trained_model, formatted_datetime_int, equation_name, model_name,\n",
    "           x_range, iterations, hid_lay, num_equations, num_heads, A_list,\n",
    "           IC_list, force_list, alpha_list, loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Single Head Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select equation parameter\n",
    "\n",
    "-   stiffness parameter $\\alpha$\n",
    "-   force function $f$\n",
    "-   initiales condition $IC$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 1\n",
    "alpha_list = [5, 10, 15, 20, 25]\n",
    "A_list = [torch.tensor([[0., -1.], [1., 2*i]], device=dev).double() for i in alpha_list]\n",
    "force_list = [torch.tensor([[0.], [0.]], device=dev).double() for _ in alpha_list]\n",
    "IC_list = [torch.tensor([[1.], [0.5]], device=dev).double() for _ in alpha_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select training parameter\n",
    "\n",
    "-   number of iterations\n",
    "-   learning rate $lr$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [0.0001, 0.0001, 0.00003, 0.00001, 0.000003]\n",
    "iterations_list = [20000, 20000, 30000, 40000, 60000]\n",
    "iterations_list = [100, 100,100, 100, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train single head model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_PINNS = []\n",
    "rng = np.random.default_rng()\n",
    "t_eval = torch.arange(x_range[0], x_range[1], 0.001, requires_grad=True, device=dev).double()\n",
    "t_eval = t_eval[np.concatenate(([0], rng.choice(range(1, len(t_eval)), size=512 - 1, replace=False)))]\n",
    "t_eval = t_eval.reshape(-1, 1)\n",
    "t_eval, _ = t_eval.sort(dim=0)\n",
    "\n",
    "for i in trange(len(alpha_list)):\n",
    "    loss_history, trained_model, _ = run_model(iterations=iterations_list[i], x_range=x_range, lr=lr_list[i], A_list=[A_list[i]], \n",
    "                                        IC_list=[IC_list[i]], force=[force_list[i]], hid_lay=hid_lay, activation=activation,\n",
    "                                        num_equations=num_equations, num_heads=num_heads, sample_size=sample_size,\n",
    "                                        decay=decay, dev=dev, verbose=False)\n",
    "    solution_PINNS.append(trained_model(t_eval)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training of the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_and_single_solution(x_range=x_range, true_functs=numerical_sol_fct,\n",
    "                              trained_model=trained_model, IC_list=IC_list, A_list=A_list,\n",
    "                              force=force_list, train_losses=loss_hist, device=dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MAE and MaxAE results over several alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_y1 = []\n",
    "mae_y2 = []\n",
    "maxae_y1 = []\n",
    "maxae_y2 = []\n",
    "\n",
    "for i in range(len(alpha_list)):\n",
    "    pinns = solution_PINNS[i].detach().cpu().numpy()\n",
    "    numerical = numerical_sol_fct(t_eval.detach().cpu().numpy(),\n",
    "                                  IC_list[0].detach().cpu().numpy(),\n",
    "                                  A_list[i].detach().cpu().numpy(),\n",
    "                                  force_list[0]).T\n",
    "    absolute_error = np.abs(pinns[:, 0, :] - numerical)\n",
    "    mae_y1.append(absolute_error.mean(0)[0])\n",
    "    mae_y2.append(absolute_error.mean(0)[1])\n",
    "    maxae_y1.append(absolute_error.max(0)[0])\n",
    "    maxae_y2.append(absolute_error.max(0)[1])\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(13, 4))\n",
    "\n",
    "ax.plot(alpha_list, mae_y1, \"-o\", label=\"$MAE$ ${y_1}$\", linewidth=2, markersize=6)\n",
    "ax.plot(alpha_list, mae_y2,\"-o\", label=\"$MAE$ ${y_2}$\", linewidth=2, markersize=6)\n",
    "ax.plot(alpha_list, maxae_y1, \"-x\", color=\"#1f77b4\", label=\"$MaxAE$ ${y_1}$\", linewidth=2, markersize=8)\n",
    "ax.plot(alpha_list, maxae_y2, \"-x\", color=\"#ff7f0e\", label=\"$MaxAE$ ${y_2}$\", linewidth=2, markersize=8)\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_title(r\"Mean and Max Absolute Error with increasing Stiffness\", fontsize=20)\n",
    "ax.set_xlabel(r'Stiffness parameter $\\alpha$ & ratio $SR$', fontsize=16)\n",
    "ax.set_ylabel('Absolute Error', fontsize=16)\n",
    "ax.set_xticks(alpha_list, [r\"$\\alpha$=\" + str(2*i) + \"\\n\" +rf\"$SR$={4*i**2}\" for i in alpha_list])\n",
    "ax.set_yticks([0.1, 0.01, 0.001, 0.0001],\n",
    "              [r\"$10^{-1}$\", r\"$10^{-2}$\", r\"$10^{-3}$\", r\"$10^{-4}$\"])\n",
    "ax.grid()\n",
    "ax.tick_params(axis='x', labelsize=14)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "ax.legend(loc='best', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save MAE and MaxAE results over several alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history[\"alpha_list\"] = alpha_list\n",
    "history[\"mae_y1\"] = mae_y1\n",
    "history[\"mae_y2\"] = mae_y2\n",
    "history[\"maxae_y1\"] = maxae_y1\n",
    "history[\"maxae_y2\"] = maxae_y2\n",
    "\n",
    "current_path = Path.cwd().parent.parent\n",
    "path = os.path.join(current_path, \"result_history\")\n",
    "with open(os.path.join(path, \"DHO_Error_Trained.json\"),  \"w\") as fp:\n",
    "    json.dump(history, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
